[["index.html", "Artifex - Fall 2023 Chapter 1 Topics in Time Series 1.1 Autocorrelation 1.2 Assignment 3 1.3 Change Points 1.4 Assignment 4", " Artifex - Fall 2023 David Reynolds 2023-10-17 Chapter 1 Topics in Time Series 1.1 Autocorrelation A central concept in time series analysis is autocorrelation. This is the correlation between \\(y_t\\) and its lagged value. For a lag of \\(h\\), this is the correlation between \\(y_t\\) and \\(y_{t-h}\\). Let’s first review correlation. For two vectors of data, \\(x\\) and \\(y\\), the correlation between the two is, \\[\\begin{align} \\text{cor}(x,y) &amp;= \\frac{\\text{cov}(x,y)}{\\sigma_x \\sigma_y} \\\\ &amp;= \\frac{ \\sum_i (x_i - \\bar{x})(y_i - \\bar{y})}{ \\sqrt{ \\sum_i (x_i - \\bar{x})^2 \\sum_i (y_i - \\bar{y})^2 }} \\end{align}\\] set.seed(1) n = 5 x = rnorm(n) y = rnorm(n) sum( (x - mean(x)) * (y - mean(y))) / ( (n-1) * sd(x) * sd(y) ) cor(x, y) The autocorrelation applies this concept to a single time series. Autocorrelation is the correlation of a time series with a delayed copy of itself as a function of delay. The autocorrelation for a time series \\(y\\) at lag \\(k\\) is: \\[\\begin{equation} r_k = \\frac{ \\sum_{t = k + 1}^{T} (y_t - \\bar{y})(y_{t-k} - \\bar{y}) }{\\sum_{t=1}^T (y_t - \\bar{y})^2 } \\end{equation}\\] Here is a simple example of computing a lag 1 autocorrelation. a = c(1,2,3,4,5) a1 = c(1,2,3,4) a2 = c(2,3,4,5) # lag 1 autocorrelation sum( (a1 - mean(a)) * (a2 - mean(a))) / (sum( (a - mean(a))^2 ) ) # by hand (acf(a)) 1.2 Assignment 3 Write a function in R that takes a vector and a lag value, \\(k\\), as arguments and outputs that autocorrelation of the vector with the lag \\(k\\) copy of itself. Compute the lag 1 through 14 acf for the Kayak visits data (group by date to get total visits per day). What do you notice? Verify the results of your function using acf. Find an economic variable of interest and compute the lag 1 through lag 10 acf of the variable. Do the same thing after applying the diff function to your data. Describe the results of this analysis. What does it tell you, if anything, about the variable you chose? 1.3 Change Points 1.3.1 CUSUM Consider the following time series \\(x_t\\), for \\(t = 1, \\ldots, 100\\). Suppose you are an analyst at an industrial company and this is a data stream from some instrument that you expect to generate random noise around 0. If there is a shift in the mean of this process, that signals trouble. Looking at this data, do you think theres any shift? It is hard to say. One method to detect change points is CUSUM. To \\[\\begin{align} y_i = \\frac{x_i - \\mu_0}{\\sigma} \\end{align}\\] Then, define two vectors, \\(C_i^+\\) and \\(C_i^-\\) whose first element is 0. Then, for \\(i \\in (2,\\ldots,T)\\), \\[\\begin{align} C_i^+ &amp;= \\text{max}(0, y_i - K + C_{i-1}^+) \\\\ C_i^- &amp;= \\text{min}(0, y_i + K + C_{i-1}^-) \\end{align}\\] The parameter \\(K\\) is typically defined as the shift in means that you hope to detect, \\(\\delta \\sigma\\), measured in standard deviations. This is implemented in the qcc package within the cusum function. 1.4 Assignment 4 "],["linear-regression-revisited.html", "Chapter 2 Linear Regression Revisited 2.1 Estimation 2.2 Example 2.3 Assignment 2", " Chapter 2 Linear Regression Revisited Let’s consider a scenario in which we have information on a response variable, \\(y\\), and \\(p\\) predictor variables organized in a design matrix \\(X\\). We want to model the conditional mean, \\(E(Y | X)\\) using a linear combination of predictor variables. So, our model is: \\[\\begin{align} y = X \\beta + \\epsilon \\end{align}\\] For now, let us assume that there is a linear relationship between \\(y\\) and \\(X\\) and that the errors (the elements of \\(\\epsilon\\)) are independent with mean of 0 and variance of \\(\\sigma^2\\). 2.1 Estimation To find the estimate for \\(\\beta\\), we can use the criteria of least squares and find the \\(\\beta\\) that minimizes the sum of the squared errors. That is, our \\(\\hat{\\beta}\\) is the vector that minimizes, \\[\\begin{align} (y - X \\beta) ^ T (y - X \\beta) \\end{align}\\] In order to minimize this function, we need some basic results for matrix derivatives. \\[\\begin{align} \\frac{\\partial}{\\partial \\beta} (A \\beta) &amp;= A \\\\ \\frac{\\partial}{\\partial \\beta} (\\beta^T M \\beta) &amp;= 2 M \\beta \\end{align}\\] 2.2 Example Let’s investigate the relationship between home prices and mortgage rates. To start, let’s use data from the quantmod package and look at the relationship between these two variables from 2000 to 2004. # https://fred.stlouisfed.org/ pr = getSymbols(&#39;MORTGAGE30US&#39;,src=&#39;FRED&#39;, warnings = F) # 30-Year Fixed Rate Mortgage Average home = getSymbols(&#39;CSUSHPINSA&#39;, src = &#39;FRED&#39;) # S&amp;P/Case-Shiller U.S. National Home Price Index # clean up dataset mort = tidy(MORTGAGE30US) %&gt;% # tidy is from the broom pkg - coerces xts object to a data frame mutate(date = ymd(index)) %&gt;% # coerce the index to be a date filter(year(date) &gt;= 2000, year(date) &lt;= 2004) %&gt;% # date range mutate(mo_year = ymd ( str_c (year(date), &quot;-&quot;, month(date), &quot;-&quot;, 01 )) ) %&gt;% # make a new date so we can group by month/year group_by(mo_year) %&gt;% summarise(val = mean(value)) %&gt;% filter(mo_year &lt; &quot;2023-08-01&quot;) home_pr = tidy(CSUSHPINSA) %&gt;% mutate(date = ymd(index)) %&gt;% filter(year(date) &gt;= 2000, year(date) &lt;= 2004) combined_dat = data.frame(mort = mort$val, pr = home_pr$value, date = home_pr$date) ggplot(combined_dat, aes( mort, pr, color = as.factor( year(date) ) ) ) + geom_point() + theme_minimal() + ggtitle(&quot;Case Shiller Index (y) and Avg. Mortgage Rates (x)&quot;) + xlab(&quot;30-Year Fixed Rate Mortgage Average&quot;) + ylab(&quot;S&amp;P/Case-Shiller U.S. National Home Price Index&quot;) How would you describe this relationship? Based on the relationship, do you think a simple linear regression model is appropriate for these data? 2.3 Assignment 2 Fit a linear regression model to these two variables and write out the model equation. Make a histogram of the residuals from this model and comment on how they correspond with the assumption of normal residuals. Plot the residuals over time. What do you see? Based on the residuals over time (plot from question 3), is there any additional variable you could add to the model to improve fit? If so, add this variable as a covariate to the linear regression and compare the fit of the augmented model with the one you fit in question 1. Currently, the 30-Year Fixed Rate Mortgage Average is around 8%. What does the model predict for the Case-Shiller Index? The current value of the Case-Shiller Index is 305. What is the residual? Now, using a scatterplot, check the relationship between these two variables for a more recent time frame (such as the last 10 years). Do you see the same relationship? Color code observations by year. "],["kayak-data-analysis.html", "Chapter 3 Kayak Data Analysis 3.1 Prompt", " Chapter 3 Kayak Data Analysis We are going to do some analysis on a dataset sent from Kayak. The prompts and data are from their data science recruiting process. To access the data, use the following code: visits = read.csv(&quot;https://raw.githubusercontent.com/dbreynol/DS809/main/data/visits.csv&quot;) conversions = read.csv(&quot;https://raw.githubusercontent.com/dbreynol/DS809/main/data/conversions.csv&quot;) channels = read.csv(&quot;https://raw.githubusercontent.com/dbreynol/DS809/main/data/channel_descriptions.csv&quot;) 3.1 Prompt One of our team’s goals is to accurately evaluate how successful our marketing campaigns are and to predict how successful future campaigns will be. In this assignment, we want you to explore how to evaluate one notion of success: conversion rate. Depending on the context, a conversion can mean different things, including a flight or hotel booking, a click on a specific part of our site, or an account sign up. Conversion rate in the first case could therefore be defined as completed flight bookings per user visit. You were given some datasets that contain a sanitized version of some of our logging data. Explore the datasets and work on the questions below. One of the CSVs contains data on daily user visits broken down by user location and marketing channel, and another contains data on conversions also broken down by user location and channel. You also have been given a file with a brief description of the channels. Do you see any interesting patterns in the data? For example, are there any seasonality trends in user visits or conversion rates (conversions/visits)? Do these seasonality trends differ between countries or channel? Can you think of any potential explanations for any of the patterns/trends/differences you saw? Which channels have the best and worst conversion rates? What reasons can you think of to explain the differences? Do you see any major conversion differences for the same channel in different countries? Predict next month’s (September 2015) aggregate conversion rates for each channel and country combination? How good are your predictions? Last time, we discussed a few ways to estimate the slope coefficient in a linear regression model. This yields a point estimate. The other key ingredient for inference is to determine how much uncertainty there is in our estimate. For the case of \\(\\hat{\\beta_1}\\), we want to know how much this estimate varies from sample to sample for the specified sample size. That is, we want to know the variance of the estimate: \\[\\begin{align} Var(\\hat{\\beta_1}). \\end{align}\\] To find what this is, let’s just try to figure out the variance directly, using the analytic formula for \\(\\hat{\\beta_1}\\) in simple linear regression: \\[\\begin{align} Var \\bigg( \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2 } \\bigg). \\end{align}\\] To carry out this calculation, recall that \\(\\text{var}(cx) = c^2 \\text{var}(x)\\). Also, recall the model assumption of independence across observations. After carrying out this calculation, we can show that, \\[\\begin{equation} Var(\\hat{\\beta}) = \\frac{\\hat{\\sigma}^2}{(n-1) \\hat{var}(x)} \\end{equation}\\] How does variation in \\(\\hat{\\beta}\\) respond to changes in sample size? How about to variation in the predictor? Before moving on, let’s write some code to make sure our calculations correspond with those generated by lm. In this case, we are able to obtain not only the variation of the estimate but also the distribution of the estimate as well as the test statistic, \\[\\begin{align} T = \\frac{\\hat{\\beta_1} - \\beta}{\\sqrt{\\text{var}\\beta}} \\sim t_{n-2} \\end{align}\\] This allows us to compute confidence intervals. For instance, if we want to compute a (1-\\(\\alpha\\)) confidence interval, note that: \\[\\begin{align} P(t_{\\alpha/2} &lt; T &lt; t_{1-\\alpha/2}) = (1-\\alpha) \\end{align}\\] "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
